
---
title: "Exercise on First Fundamental Assumption of Inferential Methods"
author: "Amirali Satvati"
output:
  html_document:
    theme: cerulean
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
``` 

```{r}
data <- read.csv(choose.files())
```
 
# Introduction

In this exercise, the data related to a study investigating the effect of daily study hours on GPA is analyzed. The primary goal is to determine the relationship between study hours (independent variable) and GPA (dependent variable) and test for normality of the residuals.

***

```{r}
asmstu <- data[sample(1:nrow(data), 50),]
head(asmstu)
model <- lm(GPA ~ Study_Hours_Per_Day, data = data)
stuGR <- model$res
head(summary(asmstu))
```

# First Fundamental Assumption 
It is assumed that the relationship between the independent and dependent variables is linear. This assumption suggests that the effect of each independent variable on the dependent variable can be expressed using a linear equation.

## Normality of Residuals

```{r}
plot(data$Study_Hours_Per_Day, data$GPA)
H <- hist(stuGR, plot = FALSE)
hist(stuGR, xlab = "Study Hours", 
     ylab = "GPA", 
     main = "Relationship Between Study Hours and GPA")
lines(H$mids, H$counts, col = "red")
boxplot(stuGR)
```

***
## Normality Test
### Kolmogorov-Smirnov Test

```{r}
ks.test(stuGR, pnorm)
```

The **p-value = 0.5759**, which is greater than the significance level (alpha). Therefore, we fail to reject the null hypothesis. The Kolmogorov-Smirnov test indicates that there is no sufficient evidence to reject the assumption of normality; the data is consistent with a normal distribution.

***
### Lilliefors Test

```{r}
ks.test((stuGR - mean(stuGR)) / sd(stuGR), pnorm)
library(nortest)
lillie.test(stuGR)
```

The null hypothesis is not rejected, indicating that the distribution of residuals is normal.

***
### Shapiro-Wilk Test

```{r}
shapiro.test(stuGR)
qqnorm(stuGR)
```

In the Shapiro-Wilk test, the null hypothesis is also not rejected, confirming that the residuals follow a normal distribution.

***

### Anderson-Darling Test

```{r}
ad.test(stuGR)
```

The Anderson-Darling test also supports the conclusion that the residuals are normally distributed.

# Second Fundamental Assumption 

It is assumed that the residuals or errors are normally distributed with a mean of zero and constant variance (homoscedasticity). Additionally, the independence of residuals is also evaluated at this level.

```{r,include=FALSE}
library(car)
library(lmtest)
```

## Scatterplot of Predicted Values and Residuals

```{r}
model <- lm(GPA ~ Study_Hours_Per_Day, data = data)
plot(fitted(model), resid(model))
```

The scatterplot does not show a funnel-shaped pattern, and the residuals appear to be randomly distributed. This suggests homoscedasticity (constant variance of errors) in the model.

## Breusch-Pagan Test  

```{r}
anova(model)
bptest(model)
```

The Breusch-Pagan test confirms that the variance of residuals is constant (homoscedasticity is present). This indicates that the linear regression model satisfies this fundamental assumption.

# Third Fundamental Assumption 

Independent variables should be non-collinear, meaning they should not have a linear relationship with each other. This ensures that the model remains meaningful and the estimates are reliable.

## Residual Autocorrelation Plot

```{r}
plot(resid(model), type = "l")
```

## Durbin-Watson Test 

```{r}
dwtest(model, alternative = "two.sided")
durbinWatsonTest(model)
```

Both Durbin-Watson tests indicate that there is no autocorrelation in the residuals of the model. This confirms that the independence assumption of residuals is satisfied, and the regression model is valid in this aspect.
