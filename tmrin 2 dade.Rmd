---
title: "تحلیل و پیش‌بینی رتبه اعضای هیئت علمی"
subtitle: "پروژه داده‌کاوی با رویکرد یادگیری ماشین"
author: "امیرعلی سطوتی"
date: "۱۴۰۴/۰۸/۰۹"
output:
  html_document:
    css: "optimized-theme.css"
    theme: default
    highlight: kate
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
    number_sections: true
    df_print: paged
    lang: fa
---
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<style>
.profile-container {
  text-align: center;
  margin-top: -20px;
  margin-bottom: 40px;
  animation: fade-up 0.8s ease-out;
}
.profile-btn {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  margin: 0 10px;
  padding: 10px 25px;
  border-radius: 50px;
  color: white !important; /* اجبار رنگ سفید */
  text-decoration: none !important;
  font-weight: bold;
  font-family: sans-serif;
  transition: all 0.3s ease;
  box-shadow: 0 4px 6px rgba(0,0,0,0.1);
}
.btn-linkedin {
  background: linear-gradient(45deg, #0077b5, #00a0dc);
}
.btn-github {
  background: linear-gradient(45deg, #333, #555);
}
.profile-btn:hover {
  transform: translateY(-3px);
  box-shadow: 0 8px 15px rgba(0,0,0,0.2);
  filter: brightness(1.1);
}
.profile-btn i {
  margin-right: 10px;
  font-size: 1.2em;
}
</style>

<div class="profile-container">
  <a href="https://www.linkedin.com/in/amirali-satvati/" target="_blank" class="profile-btn btn-linkedin">
    <i class="fab fa-linkedin"></i> LinkedIn
  </a>
  <a href="https://github.com/amiralisatvati" target="_blank" class="profile-btn btn-github">
    <i class="fab fa-github"></i> GitHub
  </a>
</div>


```{r message=FALSE, warning=FALSE, paged.print=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, digits = 2)
knitr::knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, 2)
  }
})
```




<div class="report-header">
  <div class="header-right"><strong>سیستم تحلیل داده‌های آکادمیک</strong></div>
  <div class="header-left">پروژه داده‌کاوی</div>
</div>

<div class="main-content-wrapper">


<div class="box-info">
  <p>

## بارگذاری داده‌ها و کتابخانه‌های مورد نیاز

### بارگذاری کتابخانه‌های R

اولین قدم، بارگذاری کتابخانه‌های لازم و بررسی اولیه داده‌ها برای درک ساختار، کیفیت و ویژگی‌های آماری آن است.

```{r message=FALSE, warning=FALSE}

library(caret)
library(dplyr)
library(skimr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(ggplot2)
library(patchwork)
library(forcats)
library(DT)

```

<div class="box-info"> <p> <strong>نقش هر کتابخانه در این پروژه:</strong>


ما از <code>dplyr</code> و <code>ggplot2</code> به عنوان ابزارهای اصلی برای آماده‌سازی و نمایش داده‌ها استفاده می‌کنیم. در قلب فرآیند یادگیری ماشین، کتابخانه <strong>caret</strong> قرار دارد که وظیفه تقسیم داده‌ها و مدیریت آموزش مدل را بر عهده دارد.



برای مدل‌سازی، از <strong>rpart</strong> (برای درخت تصمیم تک) و <strong>randomForest</strong> (برای روش گروهی) بهره می‌بریم. همچنین برای درک سریع وضعیت آماری داده‌ها در شروع کار، از کتابخانه قدرتمند <strong>skimr</strong> استفاده شده است. </p> </div>

### بارگذاری دیتاست


```{r}
mis <- as.data.frame(read.csv(file.choose(), header = TRUE))
```

<div class="box-info">
  <p>
  <strong>تشریح نحوه بارگذاری:</strong>
  <br>
  دستور <code>read.csv</code> تابع اصلی R برای خواندن فایل‌های متنی با جداکننده کاما است. 
  استفاده از تابع <code>file.choose()</code> در داخل آن، یک پنجره محاوره‌ای باز می‌کند تا شما بتوانید فایل را به صورت تعاملی از سیستم خود انتخاب کنید.
  <br>
  همچنین آرگومان <code>header = TRUE</code> به برنامه اعلام می‌کند که <strong>سطر اول فایل</strong> شامل نام ستون‌ها (Variables) است و نباید به عنوان داده محاسباتی در نظر گرفته شود.
  </p>
</div>

## پیش‌پردازش داده‌ها

### آمار توصیفی

```{r}
str(mis)
summary(mis)
skim(mis)
mis$X <- NULL

```

```{r}
datatable(head(mis, 100),
          options = list(
            scrollX = TRUE,
            pageLength = 5,
            dom = 'Bfrtip',
            language = list(url = '//cdn.datatables.net/plug-ins/1.10.11/i18n/Persian.json')
          ),
          caption = "جدول ۱: نمای کلی دیتاست اعضای هیئت علمی",
          rownames = FALSE,
          class = 'cell-border stripe hover'
)
```


<div class="box-result">
  <p>
  <strong>یافته‌های حاصل از بررسی ساختار داده‌ها:</strong>
  </p>
  <ul>
    <li>دستور <code>str(mis)</code>: ابعاد دقیق داده‌ها (<strong>۳۹۷ مشاهده</strong> و <strong>۷ متغیر</strong>) و نوع داده‌ها (مانند Integer برای اعداد و Factor برای دسته‌ها) را مشخص کرد.</li>
    
    <li>دستور <code>summary(mis)</code>: آماره‌های توصیفی کلیدی شامل میانگین، میانه، کمینه/بیشینه و چارک‌ها را محاسبه کرد که دید خوبی از توزیع متغیرهای عددی می‌دهد.</li>
    
    <li>دستور <code>skim(mis)</code>: این تابع قدرتمند، علاوه بر آمارهای پایه، وضعیت <strong>داده‌های گمشده (Missing Values)</strong> را به تفکیک هر ستون گزارش داد.</li>
    
    <li>اقدام اصلاحی <code>mis$X &lt;- NULL</code>: ستون X که صرفاً یک شمارنده ردیف (Index) وارد شده از فایل CSV بود و ارزش تحلیلی برای مدل‌سازی نداشت، از دیتاست حذف گردید.</li>
  </ul>
</div>

### مصورسازی داده‌ها

مصورسازی به ما کمک می‌کند تا الگوها، روابط، مقادیر پرت و توزیع داده‌ها را بهتر درک کنیم.

```{r}
par(mfrow = c(1, 4))
boxplot(mis$yrs.since.phd)
boxplot(mis$yrs.service)
boxplot(mis$salary)
boxplot(mis$salary ~ mis$rank)
par(mfrow = c(1, 3))
barplot(table(mis$rank))
barplot(table(mis$discipline))
barplot(table(mis$sex))
histogram(mis$yrs.since.phd)
histogram(mis$yrs.service)
histogram(mis$salary)
```
<div class="box-result">
  <p>
  <strong>تحلیل الگوهای بصری و آماری:</strong>
  <br>
  بررسی نمودارها حقایق مهمی را درباره ساختار داده‌ها آشکار کرد:
  </p>
  <ul>
    <li><strong>عدم توازن (Imbalance):</strong> داده‌ها در متغیرهای دسته‌ای سوگیری دارند؛ به طوری که اکثریت نمونه‌ها را رتبه «استاد تمام» (Prof) و جنسیت «مرد» تشکیل می‌دهند.</li>
    
    <li><strong>همبستگی کلیدی:</strong> نمودار جعبه‌ای <code>salary ~ rank</code> یک رابطه مستقیم و بسیار قوی را نشان می‌دهد. با ارتقای رتبه، میانه حقوق جهش قابل توجهی دارد؛ این ویژگی، <code>salary</code> را به یک پیش‌بینی‌کننده قدرتمند برای مدل تبدیل می‌کند.</li>
    
    <li><strong>توزیع متغیرهای عددی:</strong>
      <ul>
        <li>متغیر <code>yrs.since.phd</code>: توزیعی نسبتاً متقارن (شبه‌نرمال) دارد و اوج تراکم داده‌ها در بازه ۱۵ تا ۲۵ سال است.</li>
        <li>متغیر <code>yrs.service</code>: دارای <strong>چولگی به راست (Right-skewed)</strong> است، به این معنی که اکثر اساتید سابقه خدمت کمتر از ۲۵ سال دارند.</li>
        <li>متغیر <code>salary</code>: چولگی شدید به راست دارد. تمرکز اصلی حقوق‌ها در بازه ۹۰ تا ۱۱۰ هزار دلار است و وجود داده‌های پرت (Outliers) در حقوق‌های بالا کاملاً مشهود است.</li>
      </ul>
  </ul>
</div>

### پاکسازی داده‌ها


<div class="box-info">
  <p>
  <strong>استراتژی مدیریت داده‌های گمشده (Missing Values):</strong>
  <br>
  تحلیل‌ها نشان می‌دهد حدود ۱۵٪ از داده‌ها در متغیرهای <code>salary</code> و <code>discipline</code> مفقود هستند. در این مرحله تصمیم‌گیری به شرح زیر انجام شد:
  </p>
  <ul>
    <li><strong>قابلیت مدل:</strong> اگرچه مدل‌های درختی (مانند <code>rpart</code>) می‌توانند با استفاده از تکنیک «Surrogate Splits» مقادیر گمشده را مدیریت کنند، ما از این قابلیت صرف‌نظر کردیم.</li>
    
    <li><strong>رویکرد انتخابی:</strong> ما روش <strong>حذف کامل ردیف (Listwise Deletion)</strong> را انتخاب کردیم.</li>
    
    <li><strong>استدلال و ریسک:</strong> دلیل اصلی این انتخاب، ساده‌سازی تحلیل و سازگاری با توابع ارزیابی استاندارد مانند <code>caret::confusionMatrix</code> است که با مقادیر NA دچار خطا می‌شوند. 
    <br>
    <em>هشدار:</em> باید آگاه باشیم که این روش در صورتی که داده‌ها به طور تصادفی گم نشده باشند، می‌تواند باعث ایجاد <strong>اریبی (Bias)</strong> در نتایج نهایی شود.</li>
  </ul>
</div>

```{r}
mis <- mis %>% mutate(rank = as.factor(rank),discipline = as.factor(discipline),sex = as.factor(sex)) %>% na.omit() 

```
<div class="box-info">
  <p>
  <strong>گام‌های اجرایی پیش‌پردازش (Preprocessing Steps):</strong>
  </p>
  <ul>
    <li><strong>تبدیل نوع داده (Feature Encoding):</strong> با استفاده از دستور <code>mutate</code>، ستون‌های متنی (<code>rank</code>, <code>discipline</code>, <code>sex</code>) به ساختار <strong>Factor</strong> تبدیل شدند. این تبدیل برای R ضروری است تا بتواند سطوح (Levels) مختلف متغیرهای کیفی را در مدل‌سازی لحاظ کند.</li>
    
    <li><strong>پاکسازی داده‌ها (Data Cleaning):</strong> با دستور <code>na.omit</code>، استراتژی حذف کامل اعمال شد. این تابع کل دیتافریم را اسکن کرده و هر ردیفی را که حاوی حتی یک مقدار گم‌شده (NA) باشد، حذف می‌کند.</li>
  </ul>
</div>

### استدلال‌های فنی در مدیریت داده‌ها

#### ۱. مدیریت داده‌های پرت (Outliers Handling)
* **مشاهده:** نمودارهای جعبه‌ای وجود مقادیر پرت در متغیرهای `salary` و `yrs.service` را نشان دادند.
* **تحلیل فنی:** مدل‌های مبتنی بر درخت (مانند CART) ذاتاً نسبت به داده‌های پرت **مقاوم (Robust)** هستند. مکانیزم درخت بر اساس "آستانه‌های تقسیم" (Splitting Thresholds) کار می‌کند، نه میانگین یا واریانس. بنابراین، یک داده پرت (مثلاً حقوق بسیار بالا) صرفاً در یک سمتِ شرط قرار می‌گیرد و ساختار کلی مدل را منحرف نمی‌کند.
* **اقدام نهایی:** داده‌های پرت حفظ شدند و تغییری در آن‌ها ایجاد نشد.

#### ۲. مقیاس‌بندی ویژگی‌ها (Feature Scaling)
* **تحلیل فنی:** استانداردسازی (Standardization) یا نرمال‌سازی (Normalization) برای مدل‌هایی که بر اساس "فاصله اقلیدسی" کار می‌کنند (مانند KNN، SVM یا رگرسیون لجستیک) حیاتی است. اما در مدل‌های درختی، مقیاس اعداد تأثیری بر "خلوص گره‌ها" (Gini Impurity) یا انتخاب بهترین نقطه برش ندارد.
* **اقدام نهایی:** از آنجا که برای درخت تصمیم غیرضروری است، این مرحله نادیده گرفته شد (Skipped).
## ساخت مدل پیش‌بینی

### تقسیم داده به مجموعه آموزشی و آزمایشی
```{r}
set.seed(38712)
index <- createDataPartition(mis$rank, p = 0.75, list = FALSE)
train <- mis[index, ]
test <- mis[-index, ]
dim(train)
dim(test)
```

<div class="box-info">
  <p>
  <strong>تشریح فرآیند تقسیم‌بندی داده‌ها (Data Splitting):</strong>
  </p>
  <ul>
    <li><strong>تکرارپذیری (Reproducibility):</strong> دستور <code>set.seed</code> تضمین می‌کند که اعداد تصادفی تولید شده در هر بار اجرای کد، یکسان باشند. این کار برای استناد به نتایج علمی ضروری است.</li>
    
    <li><strong>نمونه‌گیری طبقه‌ای (Stratified Sampling):</strong> تابع <code>createDataPartition</code> به جای انتخاب تصادفی ساده، نسبت توزیع متغیر هدف (Rank) را در هر دو دسته حفظ می‌کند. یعنی اگر ۱۰٪ داده‌ها "دانشیار" هستند، در داده‌های آموزشی و آزمایشی نیز همین ۱۰٪ حفظ می‌شود.</li>
    
    <li><strong>نسبت تقسیم:</strong> داده‌ها به دو بخش <strong>آموزشی (۷۵٪)</strong> برای ساخت مدل و <strong>آزمایشی (۲۵٪)</strong> برای سنجش نهایی تقسیم شدند.</li>
  </ul>
</div>

### پیاده‌سازی الگوریتم درخت تصمیم (CART)

در این مرحله، ما از الگوریتم **rpart** (Recursive Partitioning and Regression Trees) برای ساخت مدل طبقه‌بندی استفاده می‌کنیم. هدف این است که قوانینی استخراج کنیم که بتوانند بر اساس ویژگی‌های موجود، رتبه علمی (Rank) را پیش‌بینی کنند.

<div class="box-info">
  <p>
  <strong>تنظیمات ساخت مدل (Model Specification):</strong>
  </p>
  <ul>
    <li><strong>فرمول <code>rank ~ .</code>:</strong> این نحوه نوشتار در R به مدل می‌گوید که <code>rank</code> متغیر هدف (Target) است و نقطه (<code>.</code>) به معنی "تمام ستون‌های دیگر موجود در دیتاست" به عنوان متغیرهای پیش‌بینی‌کننده (Predictors) است.</li>
    
    <li><strong>آرگومان <code>method = "class"</code>:</strong> از آنجا که متغیر هدف ما کیفی (Categorical) است، این پارامتر به الگوریتم دستور می‌دهد که درخت را به صورت <strong>طبقه‌بندی (Classification)</strong> بسازد و نه رگرسیون.</li>
    
    <li><strong>داده‌ها:</strong> مدل صرفاً روی داده‌های <code>train</code> آموزش می‌بیند تا بعداً بتوانیم آن را با داده‌های <code>test</code> محک بزنیم.</li>
  </ul>
</div>

```{r}
model <- rpart(rank ~ ., data = train, method = "class")
summary(model)
rpart.plot(model)
```


```{r}
# مدل بدون هرس
model1 <- rpart(rank ~ ., data = train, method = "class",
                control = rpart.control(minsplit = 5, cp = 0))
rpart.plot(model1)



```
<div class="box-result">
  <p>
  <strong>تحلیل خروجی مدل اولیه (Unpruned Tree):</strong>
  </p>
  <ul>
    <li><strong>اهمیت متغیرها (Variable Importance):</strong> 
    نتایج نشان می‌دهد که دو متغیر <code>yrs.since.phd</code> (سال‌های پس از دکترا) و <code>yrs.service</code> (سابقه خدمت) با فاصله زیاد، تأثیرگذارترین عوامل در پیش‌بینی رتبه هستند. جالب اینجاست که متغیر <code>sex</code> (جنسیت) هیچ نقشی در این مدل نداشته است.</li>
    
    <li><strong>تشخیص بیش‌برازش (Overfitting Diagnosis):</strong>
    با بررسی جدول CP (Complexity Parameter)، مشاهده می‌شود که خطای اعتبارسنجی متقابل (<code>xerror</code>) در ابتدا کاهش می‌یابد و در ۴ تقسیم (nsplit=4) به کمینه خود (۰.۲۹) می‌رسد. اما با پیچیده‌تر شدن درخت (۱۱ تقسیم)، خطا مجدداً افزایش یافته (۰.۳۱) است. این <strong>الگوی U شکل</strong> در خطا، نشان‌دهنده وقوع Overfitting در مدل کامل است.</li>
  </ul>
</div>

### استراتژی هرس کردن درخت (Pruning Strategy)

برای مقابله با بیش‌برازش و رسیدن به یک مدل تعمیم‌پذیر، باید مفاهیم زیر را در نظر بگیریم: 

[Image of overfitting underfitting optimal model diagram]


#### ۱. مفهوم بیش‌برازش و پارامتر پیچیدگی (CP)
یادگیری بیش از حد زمانی رخ می‌دهد که مدل، **نویز (Noise)** موجود در داده‌های آموزشی را به جای **سیگنال (Signal)** واقعی یاد می‌گیرد. پارامتر <code>CP</code> مکانیزمی برای جریمه کردن پیچیدگی مدل است؛ هرچه CP کمتر باشد، درخت اجازه دارد شاخ و برگ بیشتری داشته باشد و مستعد Overfitting شود.

#### ۲. تحلیل جدول CP و انتخاب بهترین مدل
ما برای انتخاب نقطه برش بهینه، به ستون <code>xerror</code> (خطای تخمین زده شده روی داده‌های دیده نشده) نگاه می‌کنیم.

* **روش حداقل خطا (Min Error):** کمترین میزان خطا برابر **۰.۵۰۰۰۰** است که در ردیف ۳ (با <code>nsplit = 2</code>) رخ داده است.

* **قانون یک خطای استاندارد (1-SE Rule):** 
    این یک رویکرد محافظه‌کارانه است که می‌گوید: «ساده‌ترین مدلی را انتخاب کن که خطای آن تفاوت معناداری با بهترین مدل نداشته باشد.»
    <br>
    <strong>محاسبات:</strong>
    <ul>
      <li>کمترین خطا (Best Error): <code>0.50000</code></li>
      <li>خطای استاندارد (SE): <code>0.07599</code></li>
      <li><strong>آستانه مجاز:</strong> $0.50000 + 0.07599 = 0.57599$</li>
    </ul>
    
    <strong>نتیجه‌گیری:</strong> مدل ردیف ۲ دارای خطای <code>0.59211</code> است که از آستانه مجاز (۰.۵۷۵۹۹) بیشتر است. بنابراین، ما همان **ردیف ۳** را به عنوان بهینه‌ترین مدل انتخاب می‌کنیم.
    
### هرس کردن مدل (Pruning)



```{r}
# مدل هرس شده با cp بهینه
best_cp <- model$cptable[which.min(model$cptable[,"xerror"]), "CP"]
pruned_model <- prune(model, cp = best_cp)
rpart.plot(pruned_model)
```
<div class="box-result">
  <p>
  <strong>ساختار نهایی درخت تصمیم (Pruned Tree Structure):</strong>
  <br>
  فرآیند هرس کردن (Pruning) منجر به ایجاد مدلی بسیار شفاف و "تفسیرپذیر" شد. نکته قابل توجه این است که از بین تمام متغیرها، تنها دو متغیر <code>yrs.since.phd</code> و <code>yrs.service</code> برای تعیین رتبه علمی کافی شناخته شدند.
  </p>
  
  <p><strong>قوانین استخراج شده (Decision Rules):</strong></p>
  <ul>
    <li>
      <strong>۱. گره ریشه (Root Node):</strong> معیار اصلی تصمیم‌گیری، سابقه دکترا است.
      <br>
      سوال: آیا <code>yrs.since.phd &lt; 12</code> است؟
      <ul>
        <li><strong>خیر (سابقه ≥ ۱۲ سال):</strong> فرد مستقیماً به عنوان <strong>Prof (استاد تمام)</strong> طبقه‌بندی می‌شود. (پوشش اکثریت داده‌ها)</li>
        <li><strong>بله (سابقه < ۱۲ سال):</strong> نیاز به بررسی شرط دوم است.</li>
      </ul>
    </li>
    
    <li>
      <strong>۲. گره فرزند (Child Node):</strong> برای افراد با سابقه دکترای کم، سابقه خدمت بررسی می‌شود.
      <br>
      سوال: آیا <code>yrs.service &gt;= 6</code> است؟
      <ul>
        <li><strong>بله:</strong> فرد به عنوان <strong>AssocProf (دانشیار)</strong> طبقه‌بندی می‌شود.</li>
        <li><strong>خیر:</strong> فرد به عنوان <strong>AsstProf (استادیار)</strong> طبقه‌بندی می‌شود.</li>
      </ul>
    </li>
  </ul>
</div>

## ارزیابی مدل

اکنون مدل هرس شده و نهایی خود را بر روی داده‌های تست (که مدل هرگز ندیده) ارزیابی می‌کنیم.


```{r}
baraz <- predict(pruned_model, test, type = "class")
cm <- confusionMatrix(data = baraz, reference = test$rank)
print(cm)
```
<div class="box-result">
  <p>
  <strong>ارزیابی عملکرد مدل بر اساس ماتریس آشفتگی (Confusion Matrix):</strong>
  <br>
  این ماتریس نقشه دقیقی از پیش‌بینی‌های درست و نادرست مدل را ارائه می‌دهد. نتایج حاصله به شرح زیر است:
  </p>
  <ul>
    <li><strong>دقت کلی (Overall Accuracy):</strong> مدل توانست با دقت <strong>۸۷.۸٪</strong> و شاخص کاپای (Kappa) <strong>۰.۷۲۸</strong> عمل کند که نشان‌دهنده عملکردی بسیار فراتر از حدس تصادفی است.</li>
    
    <li><strong>نقاط قوت (Strengths):</strong> مدل در شناسایی کلاس‌های <code>AsstProf</code> (استادیار) و <code>Prof</code> (استاد تمام) عملکرد بی‌نظیری داشت و به <strong>حساسیت (Sensitivity) ۱۰۰٪</strong> دست یافت.</li>
    
    <li><strong>نقاط ضعف (Weaknesses):</strong> پاشنه آشیل مدل، تشخیص کلاس <code>AssocProf</code> (دانشیار) است. حساسیت در این کلاس تنها <strong>۲۶.۷٪</strong> بود؛ به طوری که ۹ نفر از ۱۵ دانشیار، به اشتباه به عنوان استاد تمام پیش‌بینی شدند.</li>
  </ul>
</div>

### تحلیل تکمیلی: منحنی ROC و شاخص AUC

در مسائل طبقه‌بندی چندکلاسه (Multi-class Classification)، برای محاسبه سطح زیر منحنی (AUC)، از رویکرد **"یکی در برابر همه" (One-vs-All / OvA)** استفاده می‌شود.

اگرچه پکیج `caret` در خروجی استاندارد خود مقادیر AUC چندکلاسه را گزارش نمی‌کند، اما با توجه به حساسیت (Sensitivity) و ویژگی (Specificity) بسیار بالا در کلاس‌های **Prof** و **AsstProf**، می‌توان با اطمینان بالا استنباط کرد که:

1.  شاخص AUC برای کلاس‌های `Prof` و `AsstProf` بسیار بالا (احتمالاً **> ۰.۹۰**) است.
2.  شاخص AUC برای کلاس `AssocProf` به دلیل خطای تشخیص بالا، متوسط (احتمالاً حدود **۰.۷۹**) خواهد بود.

### تحلیل اهمیت متغیرها
```{r}
importance <- pruned_model$variable.importance
print(importance)
sorted_importance <- sort(importance)

par(mar = c(5, 7, 4, 2) + 0.1)
barplot(
  sorted_importance,
  main = "اهمیت متغیرها در مدل CART (هرس‌شده)",
  xlab = "اهمیت (Importance)",
  horiz = TRUE,
  las = 1,
  
  col = "darkred"
)
par(mar = c(5, 4, 4, 2) + 0.1)
```

<div class="box-result">
  <p>
  <strong>تفسیر کمی اهمیت متغیرها در درخت تصمیم نهایی:</strong>
  <br>
  این نمودار سهم هر متغیر را در فرآیند تصمیم‌گیری درخت (بر اساس میزان کاهش ناخالصی گره‌ها) به صورت عددی نشان می‌دهد:
  </p>
  <ul>
    <li>
      <strong>متغیرهای غالب (Dominant Predictors):</strong>
      <br>
      متغیر <code>yrs.since.phd</code> (سال‌های پس از دکترا) با امتیاز قاطع **۷۶.۵**، قوی‌ترین عامل در پیش‌بینی رتبه است. پس از آن <code>yrs.service</code> (سابقه خدمت) با امتیاز **۵۸.۸** در رتبه دوم قرار دارد.
    </li>
    
    <li>
      <strong>تطابق و اعتبار مدل:</strong>
      <br>
      این نتایج کاملاً ساختار نهایی مدل هرس‌شده را تأیید می‌کند، زیرا مدل نهایی فقط از همین دو متغیر برای ایجاد تمام قوانین تقسیم‌بندی استفاده کرده است.
    </li>
    
    <li>
      <strong>نقش متغیر حقوق (Salary):</strong>
      <br>
      متغیر <code>salary</code> با امتیاز **۳۵.۱**، اهمیت نسبی کمتری را نشان داد. این امتیاز حاکی از آن است که حقوق در مدل پیچیده‌تر و هرس‌نشده حضور داشته، اما برای تعیین قوانین نهایی به اندازه متغیرهای سابقه، کلیدی نبوده است.
    </li>
    
    <li>
      <strong>متغیرهای کم‌اهمیت:</strong>
      <br>
      متغیرهای <code>discipline</code> و <code>sex</code> به دلیل اهمیت ناچیز، در هیچ یک از قوانین تقسیم‌بندی مدل نهایی استفاده نشدند.
    </li>
  </ul>
</div>
## مقایسه با مدل جنگل تصادفی


```{r}

set.seed(38712)
rf_model <- randomForest(
  rank ~ .,
  data = train,
  ntree = 200,
  importance = TRUE
)
print(rf_model)

rf_predictions <- predict(rf_model, test, type = "class")
cm_rf <- confusionMatrix(data = rf_predictions, reference = test$rank)
print(cm_rf)

accuracy_cart <- cm$overall["Accuracy"]
accuracy_rf <- cm_rf$overall["Accuracy"]

print(paste("دقت مدل درخت تصمیم (CART):", round(accuracy_cart, 4)))
print(paste("دقت مدل جنگل تصادفی (RF):", round(accuracy_rf, 4)))


varImpPlot(rf_model, main = "اهمیت متغیرها در مدل (Random Forest)")
```
<div class="box-result">
  <p>
  <strong>تحلیل تطبیقی: درخت تصمیم (CART) در برابر جنگل تصادفی (Random Forest):</strong>
  <br>
  مدل <code>Random Forest</code> به عنوان یک روش <strong>Ensemble (گروهی)</strong> که از تجمیع آراء صدها درخت تصمیم استفاده می‌کند، تفاوت‌های عملکردی زیر را با مدل تک‌درختی نشان داد:
  </p>
  
  <ul>
    <li>
      <strong>مزایای Random Forest:</strong>
      <ul>
        <li>کاهش <strong>Overfitting</strong> از طریق میانگین‌گیری پیش‌بینی‌های چندین درخت.</li>
        <li>مقاومت بالاتر در برابر نویز و داده‌های پرت.</li>
        <li>دقت پیش‌بینی بالاتر (افزایش دقت از ۸۷.۸٪ به ۹۰٪ در این تحلیل).</li>
      </ul>
    </li>
    
    <li>
      <strong>مزایای CART (درخت تصمیم ساده):</strong>
      <ul>
        <li><strong>تفسیرپذیری کامل (Interpretability):</strong> قوانین به صورت "اگر-آنگاه" کاملاً شفاف هستند.</li>
        <li>سرعت آموزش و پیش‌بینی بسیار بالا.</li>
        <li>مناسب برای ارائه به ذینفعان غیرفنی.</li>
      </ul>
    </li>
  </ul>
  
  <p>
  <em>نکته:</em> نمودار اهمیت متغیرها در هر دو مدل یکسان بود و <code>yrs.since.phd</code> و <code>yrs.service</code> را به عنوان عوامل اصلی شناسایی کرد که اعتبار تحلیل را تایید می‌کند.
  </p>
</div>

## نتیجه‌گیری و پیشنهادات

<div class="box-result">
  <p><strong>خلاصه یافته‌های کلیدی:</strong></p>
  <ol>
    <li>
      <strong>عوامل تعیین‌کننده:</strong> متغیرهای سابقه دکترا (<code>yrs.since.phd</code>) و سابقه خدمت (<code>yrs.service</code>) قوی‌ترین پیش‌بینی‌کننده‌های رتبه آکادمیک هستند. متغیرهای جنسیت و رشته تأثیر معناداری نداشتند.
    </li>
    
    <li>
      <strong>ارزیابی عملکرد:</strong> مدل درخت تصمیم هرس‌شده با دقت <strong>۸۷.۸٪</strong> عملکرد قابل قبولی دارد. با این حال، پاشنه آشیل مدل، تشخیص کلاس <code>AssocProf</code> (دانشیار) است که اغلب با استاد تمام اشتباه گرفته می‌شود.
    </li>
    
    <li>
      <strong>شفافیت مدل:</strong> مدل نهایی به طرز شگفت‌انگیزی ساده شد و تنها با <strong>۲ قانون تصمیم‌گیری</strong> توانست اکثریت داده‌ها را به درستی طبقه‌بندی کند.
    </li>
  </ol>
  
  <hr style="border-top: 1px dashed #ccc; margin: 15px 0;">
  
  <p><strong>مسیرهای بهبود در آینده (Future Work):</strong></p>
  <ul>
    <li>جمع‌آوری داده‌های بیشتر (Over-sampling) برای کلاس <strong>AssocProf</strong> جهت رفع عدم توازن.</li>
    <li>مهندسی ویژگی (Feature Engineering): افزودن ستون‌هایی مانند "تعداد مقالات"، "h-index" یا "گرنت‌های دریافتی" برای تمایز بهتر بین رتبه‌های علمی.</li>
    <li>استفاده از روش‌های Boosting (مانند XGBoost) اگر اولویت با دقت مدل است و تفسیرپذیری اهمیت کمتری دارد.</li>
  </ul>
</div>

#### چند نکته  فراتر

```{r}

theme_set(theme_minimal())

p_rank <- ggplot(mis, aes(x = rank, fill = rank)) +
  geom_bar() +
  labs(title = "توزیع رتبه (Rank)")

p_disc <- ggplot(mis, aes(x = discipline, fill = discipline)) +
  geom_bar() +
  labs(title = "توزیع رشته (Discipline)")

p_sex <- ggplot(mis, aes(x = sex, fill = sex)) +
  geom_bar() +
  labs(title = "توزیع جنسیت (Sex)")

(p_rank | p_disc | p_sex)

p_phd_hist <- ggplot(mis, aes(x = yrs.since.phd)) +
  geom_histogram(bins = 20, fill = "skyblue", color = "black") +
  labs(title = "توزیع سال‌های پس از دکترا", x = "Yrs. Since PhD")

p_serv_hist <- ggplot(mis, aes(x = yrs.service)) +
  geom_histogram(bins = 20, fill = "salmon", color = "black") +
  labs(title = "توزیع سابقه خدمت", x = "Yrs. Service")

p_sal_hist <- ggplot(mis, aes(x = salary)) +
  geom_histogram(bins = 30, fill = "lightgreen", color = "black") +
  labs(title = "توزیع حقوق", x = "Salary")

(p_phd_hist | p_serv_hist) / (p_sal_hist)

p_phd_box <- ggplot(mis, aes(y = yrs.since.phd)) +
  geom_boxplot(fill = "skyblue") +
  labs(title = "باکس پلات سال‌های پس از دکترا") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

p_serv_box <- ggplot(mis, aes(y = yrs.service)) +
  geom_boxplot(fill = "salmon") +
  labs(title = "باکس پلات سابقه خدمت") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

p_sal_box <- ggplot(mis, aes(y = salary)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "باکس پلات حقوق") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

(p_phd_box | p_serv_box | p_sal_box)

p_rank_sal_box <- ggplot(mis, aes(x = rank, y = salary, fill = rank)) +
  geom_boxplot() +
  labs(title = "رابطه حقوق و رتبه (Salary by Rank)", x = "Rank", y = "Salary") +
  theme(legend.position = "none")

print(p_rank_sal_box)
rf_imp <- as.data.frame(importance(rf_model))
rf_imp$Variable <- rownames(rf_imp)


ggplot(rf_imp, aes(x = MeanDecreaseGini, y = fct_reorder(Variable, MeanDecreaseGini))) +
  geom_col(fill = "steelblue") +
  labs(
    title = "اهمیت متغیرها در مدل (Random Forest)",
    x = "اهمیت (MeanDecreaseGini)",
    y = "متغیر"
  ) +
  theme_minimal()


```

```{r}

par(mfrow = c(1, 2), mar = c(5, 4, 4, 2) + 0.1)

boxplot(yrs.since.phd ~ rank, 
        data = mis, 
        main = "سابقه دکترا بر اساس رتبه",
        xlab = "رتبه (Rank)",
        ylab = "سال‌های پس از دکترا",
        col = c("#0a9396", "#ee9b00", "#005f73"))

boxplot(yrs.service ~ rank, 
        data = mis, 
        main = "سابقه خدمت بر اساس رتبه",
        xlab = "رتبه (Rank)",
        ylab = "سال‌های خدمت",
        col = c("#0a9396", "#ee9b00", "#005f73"))

par(mfrow = c(1, 1))
```

#### نتیجه‌گیری نهایی

<div class="box-result">
  <p><strong>خلاصه مدیریتی و دستاوردهای تحلیل:</strong></p>
  <p>در این پروژه، مدلی موفق برای پیش‌بینی رتبه اعضای هیئت علمی توسعه یافت. نتایج به شرح زیر است:</p>
  
  <ul>
    <li>
      <strong>۱. کشف الگوهای پنهان:</strong>
      تحلیل‌ها اثبات کرد که متغیرهای زمانی، به‌ویژه <code>yrs.since.phd</code> (سال‌های پس از دکترا) و <code>yrs.service</code> (سابقه خدمت)، قوی‌ترین پیش‌بینی‌کننده‌ها هستند. در مقابل، متغیرهای دموگرافیک مانند رشته (Discipline) و جنسیت (Sex) تأثیر ناچیزی در تعیین رتبه داشتند.
    </li>
    
    <li>
      <strong>۲. تعادل بین دقت و تفسیرپذیری:</strong>
      <ul>
        <li>مدل <strong>درخت تصمیم (CART)</strong>: با وجود سادگی فوق‌العاده (تنها ۲ قانون)، به دقت قابل قبول <strong>۸۷.۸٪</strong> دست یافت که برای تصمیم‌گیری‌های شفاف مدیریتی ایده‌آل است.</li>
        <li>مدل <strong>جنگل تصادفی (Random Forest)</strong>: با پیچیدگی بیشتر، دقت را به <strong>۹۰.۰٪</strong> ارتقا داد که اعتبار متغیرهای انتخابی را تایید می‌کند.</li>
      </ul>
    </li>
    
    <li>
      <strong>۳. چالش اصلی (The Bottleneck):</strong>
      پاشنه آشیل هر دو مدل، تشخیص رتبه <strong>«دانشیار» (AssocProf)</strong> بود. مدل CART تنها ۲۶.۷٪ و مدل RF حدود ۴۰٪ از دانشیاران را درست تشخیص دادند. این نشان می‌دهد که مرز بین "دانشیار" و "استاد تمام" صرفاً با سنوات خدمت قابل تفکیک نیست.
    </li>
  </ul>
  
  <hr style="border-top: 1px dashed #10b981; margin: 15px 0;">
  
  <p><strong>پیشنهاد استراتژیک:</strong></p>
  <p>برای بهبود مدل در فازهای بعدی، پیشنهاد می‌شود علاوه بر جمع‌آوری داده‌های بیشتر برای کلاس دانشیار، از <strong>شاخص‌های عملکردی</strong> (مانند تعداد مقالات، شاخص h-index و حجم گرنت‌های پژوهشی) به عنوان متغیرهای ورودی استفاده شود.</p>
</div>

<div class="report-footer">
  تهیه شده توسط امیرعلی سطوتی | پاییز ۱۴۰۴
</div>